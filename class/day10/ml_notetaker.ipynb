{
 "metadata": {
  "name": "",
  "signature": "sha256:48eee51082791ad7dae1f1920da287dadfb7ef046d9022ab048a6404c49e9870"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Machine Learning Notetaker\n",
      "\n",
      "Use this notetaker for each algorithm so you can keep track of the important information for each algorithm\n",
      "\n",
      "## linear regression\n",
      "\n",
      "> What data problem does it solve?\n",
      "\n",
      "regression analysis (continuous, supervised learner)\n",
      "\n",
      "> How do we evaluate performance?\n",
      "\n",
      "R^2: explanation of variance in the data\n",
      "p-values: explanation of relationship of features to the target variable\n",
      "\n",
      "error: clearer relationship of error to the data, but scales with the data (to inf)\n",
      "\n",
      "> What is the output?\n",
      "\n",
      "predicted values for a y target.\n",
      "\n",
      "> What is interpretable of the algorithm?\n",
      "\n",
      "coefficients: contribution, or weights, for each feature to predict the target.\n",
      "\n",
      "y_intercept: given all weights missing, the baseline target prediction\n",
      "\n",
      "> How is it prone to overfitting?\n",
      "\n",
      "Since any 2 points make a line, and any 3 points make a plane, etc., the more features you have, the more likely the model could become overfit. Polynomials and multicollinearity make that more so.\n",
      "\n",
      "> How is it customizable?\n",
      "\n",
      "Regularization: the w parameter represents either the sum (L1) or the squared sum (L2) of the coefficients, while the hyperparameter (`alpha` in sklearn) adjusts the size of that weight\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Naive Bayes\n",
      "\n",
      "> What data problem does it solve?\n",
      "\n",
      "classification problem (categorical, supervised learner)\n",
      "\n",
      "> How do we evaluate performance?\n",
      "\n",
      "accuracy: measure of correctly predicted over number of all observations\n",
      "confusion matrix\n",
      "\n",
      "\n",
      "> What is the output?\n",
      "\n",
      "probability of y given a set of features (conditional probability)\n",
      "\n",
      "> What is interpretable of the algorithm?\n",
      "\n",
      "probability of a variable (feature) given the target (y)\n",
      "a priori: probability of y (not related to features)\n",
      "probability of features\n",
      "\n",
      "> How is it prone to overfitting?\n",
      "\n",
      "all featuers are independent of each other as likely yo overfit\n",
      "does well with small data sets\n",
      "predicts very well on larger data sets, but \"coef\" tend to be less useful\n",
      "\n",
      "> How is it customizable?\n",
      "\n",
      "- alpha\n",
      "- different versions of bayes\n",
      "> - mulinomial: counting (matrix of all numbers)\n",
      "> - bernoulli:  presence (matrix of 0s and 1s)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Decision Tree\n",
      "\n",
      "> What data problem does it solve?\n",
      "\n",
      "classification problem (categorical, supervised learner)\n",
      "regression\n",
      "\n",
      "> How do we evaluate performance?\n",
      "\n",
      "accuracy: measure of correctly predicted over number of all observations\n",
      "confusion matrix\n",
      "roc curve: plot TP vs FP rates, 0.5 is avg\n",
      "\n",
      "\n",
      "> What is the output?\n",
      "\n",
      "regression\n",
      "y = avg at nodes\n",
      "\n",
      "classification\n",
      "y = purity at each nodes (prob measure)\n",
      "\n",
      "> What is interpretable of the algorithm?\n",
      "\n",
      "\"feature importance\": normalized to 1\n",
      "rule sets: graphviz!\n",
      "\n",
      "> How is it prone to overfitting?\n",
      "\n",
      "too many nodes => overfit\n",
      "\n",
      "> How is it customizable?\n",
      "\n",
      "max_depth: number of nodes\n",
      "min sample split: min has to be 2\n",
      "min_samples_leaf: min to consider in a leaf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}