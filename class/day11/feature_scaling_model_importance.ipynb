{
 "metadata": {
  "name": "",
  "signature": "sha256:235765f5f94676ea48e1244c56beb539a09e35fbb0cf7c83ceb1a7f524016c56"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Normalizing to 0 and 1 (where 0 remains 0)**\n",
      "\n",
      "$x^` = \\dfrac{x_0}{max(x)}$\n",
      "\n",
      "\n",
      "**Normalizing to 0 and 1 (where min == 0)**\n",
      "\n",
      "$x^` = \\dfrac{x_0 - min(x)}{max(x) - min(fx))}$\n",
      "\n",
      "**Normalizing to -1 and 1 (where mean == 0)**\n",
      "\n",
      "$x^` = \\dfrac{x_0 - mean(x)}{max(x) - mean(x)}$\n",
      "\n",
      "**Standardization using mean and standard deviation (where mean = 0)**\n",
      "\n",
      "Standardization is a slightly different process for normalizing where our data splits are represented using standard deviations instead.\n",
      "\n",
      "$x^` = \\dfrac{x_0 - mean(x)}{std(x))}$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from __future__ import division\n",
      "\n",
      "class Transformations(object):\n",
      "    \"\"\"since these transformations are all related, we'll nest them all under a feature norm class\"\"\"\n",
      "    def mean_at_zero(self, arr):\n",
      "        return np.array([i - np.mean(arr) for i in arr])\n",
      "\n",
      "    def norm_to_min_zero(self, arr):\n",
      "        return np.array([i / max(arr) for i in arr])\n",
      "    \n",
      "    def norm_to_absolute_min_zero(self, arr):\n",
      "        \"\"\"should be a range of 0 to 1, where 0 maintains its 0 value\"\"\"\n",
      "        return np.array([(i - min(arr)) / (max(arr) - min(arr)) for i in arr])\n",
      "        \n",
      "    def norm_to_neg_pos(self, arr):\n",
      "        \"\"\"should be a range of -1 to 1, where 0 represents the mean\"\"\"\n",
      "        return np.array([(i - np.mean(arr)) / (max(arr) - np.mean(arr)) for i in arr])\n",
      "        \n",
      "    def norm_by_std(self, arr):\n",
      "        \"\"\"should be a range where 0 represents the mean\"\"\"\n",
      "        return np.array([(i - np.mean(arr)) / (np.std(arr)) for i in arr])\n",
      "\n",
      "## tests to make sure we built this correctly:\n",
      "transformer = Transformations()\n",
      "a = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
      "print transformer.mean_at_zero(a) == np.array([-2, -1, 0, 1, 2])\n",
      "print transformer.norm_to_min_zero(a) == np.array([0.2, 0.4, 0.6, 0.8, 1.0])\n",
      "print transformer.norm_to_absolute_min_zero(a) == np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n",
      "print transformer.norm_to_neg_pos(a) == np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n",
      "print transformer.norm_by_std(a) == np.array([-1.414213562373095, -0.7071067811865475, 0.0, 0.7071067811865475, 1.414213562373095])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ True  True  True  True  True]\n",
        "[ True  True  True  True  True]\n",
        "[ True  True  True  True  True]\n",
        "[ True  True  True  True  True]\n",
        "[ True  True  True  True  True]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "print a\n",
      "print preprocessing.scale(a, with_mean=True, with_std=False)\n",
      "print preprocessing.scale(a, with_mean=True, with_std=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.  2.  3.  4.  5.]\n",
        "[-2. -1.  0.  1.  2.]\n",
        "[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy as sp\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "class PowerLaw(object):\n",
      "    def fit(self, x, y, transform=True):\n",
      "        \"\"\"\n",
      "        returns back the amplitude and index of a powerlaw relationship.\n",
      "        assumes the data is not already log10 transformed.\n",
      "        return: [index, amp], also stored on the instance\n",
      "        \"\"\"\n",
      "        if transform:\n",
      "            x = np.log10(x)\n",
      "            y = np.log10(y)\n",
      "        # define our (line) fitting function and error function to optimize on\n",
      "        fitfunc = lambda p, x: p[0] + p[1] * x\n",
      "        errfunc = lambda p, x, y: (y - fitfunc(p, x))\n",
      "        # defines a starting point to optimize from.\n",
      "        p_init = [1.0, -1.0] \n",
      "        out = sp.optimize.leastsq(errfunc, p_init, args=(x, y), full_output=1)\n",
      "        result = out[0]\n",
      "        self.index = result[1]\n",
      "        self.amp = 10.0**result[0]\n",
      "        return np.array([self.amp, self.index])\n",
      "    \n",
      "    def transform(self, x):\n",
      "        \"\"\"returns the x-transformed data\"\"\"\n",
      "        return self.amp * (x**self.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('/Users/Ikkei/data-analysis/DAT18NYC/data/lemons_description.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}